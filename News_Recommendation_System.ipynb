{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJF0tPXa4Z2Ff1y9F7cHii",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/selete-tetteh/News-Recommendation-System/blob/main/News_Recommendation_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.cluster.hierarchy import ward, dendrogram\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import re\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "ooyZQKqUMkvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "news_data = pd.read_csv('/content/result_final.csv', usecols=['date', 'title', 'text', 'link'])\n",
        "\n",
        "# Drop rows with missing values\n",
        "news_data.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "BIB6d1D6Mp_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply text preprocessing functions\n",
        "def make_lowercase(text):\n",
        "    return text.lower()\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    stops = set(stopwords.words(\"english\"))\n",
        "    text = [w for w in text.split() if w not in stops and w.isalpha()]\n",
        "    return \" \".join(text)\n",
        "\n",
        "def remove_punctuation_marks(text):\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    text = tokenizer.tokenize(text)\n",
        "    return \" \".join(text)\n",
        "\n",
        "def remove_html_tags(text):\n",
        "    html_pattern = re.compile('<.*?>')\n",
        "    return html_pattern.sub(r'', text)"
      ],
      "metadata": {
        "id": "mAl1Z-GIMvGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_data['cleaned_desc'] = news_data['text'].apply(make_lowercase).apply(remove_stopwords).apply(remove_punctuation_marks).apply(remove_html_tags)\n",
        "\n",
        "# Drop duplicate rows\n",
        "news_data.drop_duplicates(subset=None, keep='first', inplace=True)\n",
        "\n",
        "# Add ID column\n",
        "news_data.insert(0, 'id', range(news_data.shape[0]))"
      ],
      "metadata": {
        "id": "lKyusFWeEeAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(df):\n",
        "    tf = TfidfVectorizer(analyzer='word', stop_words='english', max_df=0.8, min_df=0.0, use_idf=True, ngram_range=(1,3))\n",
        "    tfidf_matrix = tf.fit_transform(df['cleaned_desc'])\n",
        "    return tfidf_matrix, tf.get_feature_names_out() \n",
        "\n",
        "def cluster_articles(tfidf_matrix, num_clusters):\n",
        "    km = KMeans(n_clusters=num_clusters)\n",
        "    km.fit(tfidf_matrix)\n",
        "    clusters = km.labels_.tolist()\n",
        "    return clusters\n",
        "\n",
        "def recommend_similar_articles(df, article_id, num_articles, tfidf_matrix, clusters):\n",
        "    idx = df.index[df['id'] == article_id].tolist()[0]\n",
        "    similarity_score = list(enumerate(cosine_similarity(tfidf_matrix[idx], tfidf_matrix)[0]))\n",
        "    similarity_score = sorted(similarity_score, key=lambda x: x[1], reverse=True)\n",
        "    similarity_score = similarity_score[1:num_articles + 1]\n",
        "    news_indices = [i[0] for i in similarity_score]\n",
        "    print(\"Article Read --\", df['title'].iloc[idx], \"link:\", df['link'].iloc[idx])\n",
        "    print(\" ---------------------------------------------------------- \")\n",
        "    for i, news_index in enumerate(news_indices, start=1):\n",
        "        print(f\"Recommendation {i}: {df['title'].iloc[news_index]} || Link --{df['link'].iloc[news_index]} (score: {similarity_score[i-1][1]:.2f})\")\n"
      ],
      "metadata": {
        "id": "KWOjP2CXNAXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = news_data"
      ],
      "metadata": {
        "id": "HBgMPat-MGol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "tfidf_matrix, feature_names = preprocess_data(df)"
      ],
      "metadata": {
        "id": "X7MzpGdvqFzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cluster the articles\n",
        "num_clusters = 5\n",
        "clusters = cluster_articles(tfidf_matrix, num_clusters)"
      ],
      "metadata": {
        "id": "xdZOcK3PqAGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommend similar articles for a given article ID\n",
        "article_id = 20\n",
        "num_articles = 15\n",
        "recommend_similar_articles(df, article_id, num_articles, tfidf_matrix, clusters)"
      ],
      "metadata": {
        "id": "3ksNu1tdEpMZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}